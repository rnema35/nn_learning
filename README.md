A repo to implement different concepts I've learned about neural nets in a simple manner, to imporve my conceptional understanding and coding skills

-main.py is the one where I have all the tests

-try_one is just me reading blogs and getting comfortable with the code and thought process
-nn.py is the first working neural net, is fixed with the only relu activation functions, had all the functions defined inside
    -Mainly focused on a linear activation function

-nn2.py is the one where I added support for different activation functions and made a seperate class to define layers, makes use of a seperate file to keep all my functions
    -functions.py is where all the helper math functions are stored
    -Got ReLu and Sigmoid working (in tandem as well)
    -going to eventually work to make convolution work as well

-rnn.py is going to be for RNNS and LSTMs lol, no idea how this is going to go

Resources:
http://neuralnetworksanddeeplearning.com/chap1.html by Micheal Neilson (for traditional NN)
https://www.freecodecamp.org/news/building-a-neural-network-from-scratch/ by Aditya (for traditional NN)
https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks by Afshine Amidi and Shervine Amidi (for RNN)
